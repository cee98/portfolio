# Deep Learning for Segmentation of the Fetal Face From T2W Fetal MRI

## Problem description:
Assessing fetal craniomaxillofacial malformalities,affecting soft tissue and bone, through 3D Magnetic Resonance Imaging (MRI) provides anatomical details of such conditions that arise congenitally, due to good soft tissue contrast, and
the advantage of examining such features from multiple planes. Having detailed segmentations is essential for planning and implementing high-quality postnatal care since these abnormalities can greatly affect the newbornâ€™s wellbeing. However, segmentations
are usually derived manually, posing challenges such as its time-consuming nature, and potential for interobserver variability. Therefore, using Deep Learning (DL) techniques provides
automated segmentations with an accurate degree, contributing to further comprehending anatomical characteristics of orofacial conditions. DL medical segmentation techniques have been widely applied to cardiology, neurology, and placental health
in fetal medicine, but still lacks research regarding craniofacial development. This study aims to implement and evaluate DL pipelines for the segmentation of the fetal face from 3D T2-weighted fetal MRI.

## Feature variables:
There is 90 regions and matrices have 90x90 values, giving rise to a total of 4005 features.
## Target variables:
1 - premature <br>
0 - term-born

## Programming language:
Python 

## Libraries:
Scikit-learn, Pandas, NumPy, Matplotlib

## Algorithms:
- Principal Component Analysis (PCA)
- Feature Selection using ANOVA F-value (f_classif)
- StandardScaler for feature scaling
- SelectKBest for selecting top k features based on the ANOVA F-value
- Train-test split for splitting the dataset into training and testing sets
- Cross-validation for model evaluation (using cross_val_score and cross_val_predict)
- GridSearchCV for hyperparameter tuning of models

## Models built:
Logistic Regression Classifier and Random Forest Classifier

## Methods of model evaluation
Accuracy, Sensitivity, Specificity, Recall

## Summary of Results:


In comparing the test set results across different classifiers and feature selection techniques, the following observations can be made:

Logistic Regression Classifier:<br>
Accuracy: 0.94<br>
Sensitivity: 0.76<br>
Specificity: 0.99<br>
Mean recall: 0.88<br>

Logistic Regression Classifier with SelectKBest:<br>
Accuracy: 0.93<br>
Sensitivity: 0.76<br>
Specificity: 0.97<br>
Mean recall: 0.87<br>

Random Forest Classifier:<br>
Accuracy: 0.84<br>
Sensitivity: 0.65<br>
Specificity: 0.89<br>
Mean recall: 0.77<br>

Random Forest Classifier with SelectKBest:<br>
Accuracy: 0.86<br>
Sensitivity: 0.71<br>
Specificity: 0.90<br>
Mean recall: 0.80<br>

From these results:<br>

- Logistic Regression Classifier exhibits the highest accuracy and specificity among all models, indicating its effectiveness in correctly classifying instances and distinguishing between classes.
- Random Forest Classifier, while having decent accuracy, shows lower sensitivity compared to Logistic Regression, suggesting it may misclassify positive instances more often.
- Feature selection using SelectKBest did not significantly improve the performance metrics in this scenario. However, it slightly affects the accuracy and specificity of both classifiers.
- Despite the Random Forest model having slightly lower accuracy and sensitivity, both models have comparable cross-validation scores, indicating similar generalization performance, when compared to both logistic regression classifiers which exhibit overfitting.
- Overall, Logistic Regression Classifier performs the best in terms of accuracy and specificity, making it a suitable choice for this classification task.

## Limitations:
- There were a large number of features compared to the number of samples, so the classifiers were prone to overfitting.
- The dataset used was unbalanced so the smaller class (preterm) will be more difficult to predict correctly.



